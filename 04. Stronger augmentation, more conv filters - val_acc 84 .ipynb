{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Version 4\n",
    "# Manual loading images, image data generator\n",
    "# Similiar network structure but with more filters in both convolutional layers\n",
    "# CHANGE: Rotation range 4 degrees, horizontal flip - efectively around 4 times the data from version 3\n",
    "# Conclusion - stronger image augmentation can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#all imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#import cv2\n",
    "import csv\n",
    "import imageio\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('th')\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "def readimagesfromfolder(path, color, show):\n",
    "\timagepackage_list = []\n",
    "\timagepackage = []\n",
    "\timagelist = []\n",
    "\tfilelist = sorted(os.listdir(path))\n",
    "\tfor filename in filelist:\n",
    "\t\tfullfilename =  path + filename\n",
    "\t\t#print(fullfilename)        \n",
    "\t\tsingleimage = imageio.imread(fullfilename)\n",
    "\t\tsingleimage = rgb2gray(singleimage)\n",
    "\t\t#print(singleimage)        \n",
    "\t\tif show==1:\n",
    "\t\t\tplt.imshow(singleimage)\n",
    "\t\t\tplt.show()\n",
    "\t\timagepackage.append(singleimage)\n",
    "\t\timagepackage_list.append(imagepackage)        \n",
    "\t\timagepackage = []        \n",
    "\t#print(len(imagepackage))        \n",
    "\timagepackage_list = np.float32(imagepackage_list)\n",
    "\t#cv2.destroyAllWindows()\n",
    "\treturn imagepackage_list\n",
    "\n",
    "def readlabelfromcsv(filename):\n",
    "    training_y = []\n",
    "    with open(filename) as f:\n",
    "        #training_y.append(f.readline())\n",
    "        content = csv.reader(f)\n",
    "        for line in content:\n",
    "            #print(line[0])\n",
    "            training_y.append(int(line[0]))\n",
    "    return training_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 1, 180, 180)\n",
      "(48, 1, 180, 180)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "(162,)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "folderpath = 'data/basic/training/'\n",
    "X_train=readimagesfromfolder(folderpath, 0, 0)\n",
    "print(np.shape(X_train))\n",
    "\n",
    "folderpath = 'data/basic/test/'\n",
    "X_test=readimagesfromfolder(folderpath, 0, 0)\n",
    "print(np.shape(X_test))\n",
    "\n",
    "y_train = readlabelfromcsv(\"data/basic/training.csv\")\n",
    "y_test = readlabelfromcsv(\"data/basic/test.csv\")\n",
    "\n",
    "print(y_train)\n",
    "print(np.shape(y_train))\n",
    "\n",
    "print(y_test)\n",
    "print(np.shape(y_test))\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=4,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py:1462: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58s - loss: 0.6400 - acc: 0.7248 - val_loss: 0.5373 - val_acc: 0.6875\n",
      "Epoch 2/20\n",
      "22s - loss: 0.3488 - acc: 0.8720 - val_loss: 0.6131 - val_acc: 0.7708\n",
      "Epoch 3/20\n",
      "23s - loss: 0.2551 - acc: 0.9099 - val_loss: 0.6029 - val_acc: 0.8125\n",
      "Epoch 4/20\n",
      "23s - loss: 0.1155 - acc: 0.9616 - val_loss: 0.7018 - val_acc: 0.7917\n",
      "Epoch 5/20\n",
      "23s - loss: 0.0797 - acc: 0.9714 - val_loss: 0.6518 - val_acc: 0.8125\n",
      "Epoch 6/20\n",
      "22s - loss: 0.0481 - acc: 0.9838 - val_loss: 1.2167 - val_acc: 0.7917\n",
      "Epoch 7/20\n",
      "22s - loss: 0.0672 - acc: 0.9772 - val_loss: 0.6650 - val_acc: 0.8125\n",
      "Epoch 8/20\n",
      "22s - loss: 0.0334 - acc: 0.9878 - val_loss: 0.8986 - val_acc: 0.7708\n",
      "Epoch 9/20\n",
      "22s - loss: 0.0360 - acc: 0.9882 - val_loss: 0.9701 - val_acc: 0.7708\n",
      "Epoch 10/20\n",
      "22s - loss: 0.0290 - acc: 0.9892 - val_loss: 0.9369 - val_acc: 0.7917\n",
      "Epoch 11/20\n",
      "22s - loss: 0.0206 - acc: 0.9934 - val_loss: 1.0981 - val_acc: 0.7292\n",
      "Epoch 12/20\n",
      "22s - loss: 0.0187 - acc: 0.9938 - val_loss: 0.9198 - val_acc: 0.8125\n",
      "Epoch 13/20\n",
      "22s - loss: 0.0162 - acc: 0.9946 - val_loss: 0.7820 - val_acc: 0.8125\n",
      "Epoch 14/20\n",
      "22s - loss: 0.0210 - acc: 0.9918 - val_loss: 0.6154 - val_acc: 0.8125\n",
      "Epoch 15/20\n",
      "22s - loss: 0.0437 - acc: 0.9864 - val_loss: 0.9225 - val_acc: 0.8333\n",
      "Epoch 16/20\n",
      "22s - loss: 0.0352 - acc: 0.9890 - val_loss: 0.7238 - val_acc: 0.7917\n",
      "Epoch 17/20\n",
      "22s - loss: 0.0204 - acc: 0.9944 - val_loss: 0.6415 - val_acc: 0.8333\n",
      "Epoch 18/20\n",
      "22s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.8709 - val_acc: 0.8542\n",
      "Epoch 19/20\n",
      "23s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9657 - val_acc: 0.8542\n",
      "Epoch 20/20\n",
      "22s - loss: 0.0320 - acc: 0.9912 - val_loss: 0.7566 - val_acc: 0.8333\n",
      "[0.75664357344309485, 0.83333333333333337]\n",
      "Baseline Error: 16.67%\n"
     ]
    }
   ],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(24, 5, 5, border_mode='valid', input_shape=(1, 180, 180), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(16, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=16),samples_per_epoch = 5000, nb_epoch = 20, verbose=2, validation_data=(X_test, y_test))\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print scores\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
